{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a9326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\craft_model\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0774c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import craft_utils\n",
    "import imgproc\n",
    "import file_utils\n",
    "import json\n",
    "import zipfile\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from craft import CRAFT\n",
    "\n",
    "from collections import OrderedDict\n",
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1501324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n",
    "    t0 = time.time()\n",
    "    canvas_size=2280\n",
    "    mag_ratio=1.5\n",
    "    show_time=False\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        y, feature = net(x)\n",
    "\n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        with torch.no_grad():\n",
    "            y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n",
    "\n",
    "    t0 = time.time() - t0\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "    t1 = time.time() - t1\n",
    "\n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "\n",
    "    if show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes, polys, ret_score_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bfae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(img):          # RGB order\n",
    "    if img.shape[0] == 2: img = img[0]\n",
    "    if len(img.shape) == 2 : img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    if img.shape[2] == 4:   img = img[:,:,:3]\n",
    "    img = np.array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24592f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import file_utils\n",
    "def zoom(img, zx=10,zy=15):\n",
    "    return cv.resize(img, None, fx=zx, fy=zy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62da8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/image1.jpg')\n",
    "cropped = img[0:img.shape[0],200:1400]\n",
    "zoomed = zoom(img)\n",
    "zoomed_and_cropped = zoom(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e59a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5cf1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n",
    "    t0 = time.time()\n",
    "    canvas_size=2280\n",
    "    mag_ratio=1.5\n",
    "    show_time=False\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        y, feature = net(x)\n",
    "\n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        with torch.no_grad():\n",
    "            y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n",
    "\n",
    "    t0 = time.time() - t0\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "    t1 = time.time() - t1\n",
    "\n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "\n",
    "    if show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes, polys, ret_score_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2140fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crafttry(img):\n",
    "    net = CRAFT()     # initialize\n",
    "    trained_model='weights/craft_mlt_25k.pth'\n",
    "    text_threshold=0.7\n",
    "    low_text=0.5\n",
    "    link_threshold=.9\n",
    "    cuda=False\n",
    "    canvas_size=1280\n",
    "    \n",
    "    poly=False\n",
    "    \n",
    "    refine=False\n",
    "    refiner_model='weights/craft_refiner_CTW1500.pth'\n",
    "    \n",
    "    result_folder = './result/'\n",
    "    if not os.path.isdir(result_folder):\n",
    "        os.mkdir(result_folder)\n",
    "    print('Loading weights from checkpoint (' + trained_model + ')')\n",
    "    if cuda:\n",
    "        net.load_state_dict(copyStateDict(torch.load(trained_model)))\n",
    "    else:\n",
    "        net.load_state_dict(copyStateDict(torch.load(trained_model, map_location='cpu')))\n",
    "\n",
    "    if cuda:\n",
    "        net = net.cuda()\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = False\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    # LinkRefiner\n",
    "    refine_net = None\n",
    "    if refine:\n",
    "        from refinenet import RefineNet\n",
    "        refine_net = RefineNet()\n",
    "        print('Loading weights of refiner from checkpoint (' + refiner_model + ')')\n",
    "        if cuda:\n",
    "            refine_net.load_state_dict(copyStateDict(torch.load(refiner_model)))\n",
    "            refine_net = refine_net.cuda()\n",
    "            refine_net = torch.nn.DataParallel(refine_net)\n",
    "        else:\n",
    "            refine_net.load_state_dict(copyStateDict(torch.load(refiner_model, map_location='cpu')))\n",
    "\n",
    "        refine_net.eval()\n",
    "        poly = True\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    # load data\n",
    "#     print(\"Test image {:d}/{:d}: {:s}\".format(k+1, len(image_list), image_path), end='\\r')\n",
    "    image =loadImage(img)\n",
    "\n",
    "    bboxes, polys, score_text = test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net)\n",
    "#         print(bboxes)\n",
    "        # save score text\n",
    "#     filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "    mask_file = result_folder + \"/vallires_crop_mask.jpg\"\n",
    "    cv2.imwrite(mask_file, score_text)\n",
    "    \n",
    "    file_utils.saveResult(\"/\", image[:,:,::-1], polys, dirname=result_folder)\n",
    "    f1 = result_folder + \"/res_.jpg\"\n",
    "    display(Image(filename=f1))\n",
    "\n",
    "    print(\"elapsed time : {}s\".format(time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f08426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (weights/craft_mlt_25k.pth)\n"
     ]
    }
   ],
   "source": [
    "crafttry(zoomed_and_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"result/res_.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craft",
   "language": "python",
   "name": "craft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
